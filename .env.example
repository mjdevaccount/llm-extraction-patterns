# LLM Provider Configuration
LLM_PROVIDER=openai  # Options: openai, anthropic, ollama
LLM_MODEL=gpt-4

# API Keys (only needed for cloud providers)
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...

# Local LLM (Ollama)
OLLAMA_BASE_URL=http://localhost:11434

# MCP Server
MCP_SERVER_URL=http://localhost:8000

# Logging
LOG_LEVEL=INFO
